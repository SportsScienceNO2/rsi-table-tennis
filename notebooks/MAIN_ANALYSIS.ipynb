{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b899dac-208d-46d5-b568-fabfa813d82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "             RELIABILITY REPORT: CONSISTENCY & PRECISION\n",
      "======================================================================\n",
      "                  Test  n                    CV (%)                   ICC (3,1)\n",
      "               SJ (cm) 30        6.64 (Good (<10%))    0.937 (Excellent (>0.9))\n",
      "              CMJ (cm) 30        4.04 (Good (<10%))    0.972 (Excellent (>0.9))\n",
      "              RSI 15cm 30 13.41 (Moderate (10-20%))     0.893 (Good (0.75-0.9))\n",
      "              RSI 30cm 30 16.86 (Moderate (10-20%))     0.816 (Good (0.75-0.9))\n",
      "              RSI 45cm 29       20.45 (Poor (>20%)) 0.735 (Moderate (0.5-0.75))\n",
      "         Sprint 5m (s) 32        3.69 (Good (<10%))    0.953 (Excellent (>0.9))\n",
      "        Sprint 10m (s) 32        2.52 (Good (<10%))    0.981 (Excellent (>0.9))\n",
      "            T-Test (s) 30        4.37 (Good (<10%))     0.899 (Good (0.75-0.9))\n",
      "       Square Test (s) 30        3.10 (Good (<10%))     0.900 (Good (0.75-0.9))\n",
      "    Handgrip Dom (kgf) 32        7.70 (Good (<10%))    0.966 (Excellent (>0.9))\n",
      "Handgrip Non-Dom (kgf) 30        8.15 (Good (<10%))    0.934 (Excellent (>0.9))\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "             NORMALITY REPORT: SHAPIRO-WILK BY GROUP\n",
      "======================================================================\n",
      "       Group            Variable  W Stat  p-value Normal? Recommended Analysis\n",
      "Convencional             SJ Best   0.953   0.4434     Yes           Parametric\n",
      "Convencional            CMJ Best   0.954   0.4609     Yes           Parametric\n",
      "Convencional    Drop 30 RSI Best   0.918   0.1048     Yes           Parametric\n",
      "Convencional      Sprint 5m Best   0.895   0.0392      No       Non-Parametric\n",
      "Convencional     Sprint 10m Best   0.884   0.0254      No       Non-Parametric\n",
      "Convencional         Test T Best   0.946   0.3380     Yes           Parametric\n",
      "Convencional         Square Best   0.950   0.3994     Yes           Parametric\n",
      "Convencional Handgrip Total Best   0.878   0.0199      No       Non-Parametric\n",
      "Convencional      Radar Vel Best   0.945   0.3279     Yes           Parametric\n",
      "Convencional   Target Efficiency   0.869   0.0138      No       Non-Parametric\n",
      "Para-athlete             SJ Best   0.985   0.9886     Yes           Parametric\n",
      "Para-athlete            CMJ Best   0.962   0.7964     Yes           Parametric\n",
      "Para-athlete    Drop 30 RSI Best   0.947   0.5997     Yes           Parametric\n",
      "Para-athlete      Sprint 5m Best   0.794   0.0058      No       Non-Parametric\n",
      "Para-athlete     Sprint 10m Best   0.758   0.0023      No       Non-Parametric\n",
      "Para-athlete         Test T Best   0.965   0.8272     Yes           Parametric\n",
      "Para-athlete         Square Best   0.913   0.2648     Yes           Parametric\n",
      "Para-athlete Handgrip Total Best   0.864   0.0431      No       Non-Parametric\n",
      "Para-athlete      Radar Vel Best   0.937   0.4169     Yes           Parametric\n",
      "Para-athlete   Target Efficiency   0.772   0.0033      No       Non-Parametric\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# =============================================================================\n",
    "# COMPREHENSIVE STATISTICAL REPORT: RELIABILITY AND NORMALITY\n",
    "# Version: 7.1 (Expanded Battery for Open Science)\n",
    "# This script standardizes headers, cleans numeric data, and computes\n",
    "# measurement consistency and distribution assumptions for the full dataset.\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_preprocess(file_path):\n",
    "    \"\"\"Loads CSV, standardizes headers, decimals, and handles missing values.\"\"\"\n",
    "    df = pd.read_csv(file_path, sep=';')\n",
    "    \n",
    "    # 1. Standardize headers: Replace multiple spaces with a single space and strip\n",
    "    df.columns = df.columns.str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "    \n",
    "    # 2. Convert to numeric rigorously\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].astype(str).str.strip().str.replace(',', '.', regex=False)\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "    return df\n",
    "\n",
    "def calculate_reliability(data, trial_cols, test_name):\n",
    "    \"\"\"Calculates CV% and ICC (3,1) for test-retest consistency.\"\"\"\n",
    "    clean_pairs = data[trial_cols].dropna()\n",
    "    n = len(clean_pairs)\n",
    "    k = 2 \n",
    "    \n",
    "    if n < 2:\n",
    "        return {'Test': test_name, 'n': n, 'CV (%)': 'N/A', 'ICC (3,1)': 'N/A'}\n",
    "\n",
    "    diff = clean_pairs.iloc[:, 0] - clean_pairs.iloc[:, 1]\n",
    "    typical_error = np.std(diff, ddof=1) / np.sqrt(2)\n",
    "    grand_mean = clean_pairs.values.mean()\n",
    "    cv = (typical_error / grand_mean) * 100\n",
    "    \n",
    "    all_data = clean_pairs.values\n",
    "    ms_between_subjects = (k * np.sum((np.mean(all_data, axis=1) - grand_mean)**2)) / (n - 1)\n",
    "    ms_error = (np.sum((all_data - grand_mean)**2) - \n",
    "                k * np.sum((np.mean(all_data, axis=1) - grand_mean)**2) - \n",
    "                n * np.sum((np.mean(all_data, axis=0) - grand_mean)**2)) / ((n - 1) * (k - 1))\n",
    "    \n",
    "    icc = (ms_between_subjects - ms_error) / (ms_between_subjects + (k - 1) * ms_error)\n",
    "    \n",
    "    cv_eval = \"Good (<10%)\" if cv < 10 else \"Moderate (10-20%)\" if cv < 20 else \"Poor (>20%)\"\n",
    "    icc_eval = \"Excellent (>0.9)\" if icc > 0.9 else \"Good (0.75-0.9)\" if icc > 0.75 else \"Moderate (0.5-0.75)\" if icc > 0.5 else \"Poor (<0.5)\"\n",
    "    \n",
    "    return {\n",
    "        'Test': test_name, 'n': n,\n",
    "        'CV (%)': f\"{cv:.2f} ({cv_eval})\",\n",
    "        'ICC (3,1)': f\"{icc:.3f} ({icc_eval})\"\n",
    "    }\n",
    "\n",
    "def perform_normality_test(data, variables, group_col, raw_df):\n",
    "    \"\"\"Performs Shapiro-Wilk normality test grouped by specific categories.\"\"\"\n",
    "    report = []\n",
    "    data[group_col] = raw_df[group_col].str.strip()\n",
    "    groups = data[group_col].dropna().unique()\n",
    "    \n",
    "    for group in groups:\n",
    "        group_data = data[data[group_col] == group]\n",
    "        for var in variables:\n",
    "            if var in group_data.columns:\n",
    "                values = group_data[var].dropna()\n",
    "                if len(values) >= 3:\n",
    "                    w_stat, p_val = stats.shapiro(values)\n",
    "                    report.append({\n",
    "                        'Group': group, 'Variable': var,\n",
    "                        'W Stat': round(w_stat, 3), 'p-value': round(p_val, 4),\n",
    "                        'Normal?': 'Yes' if p_val > 0.05 else 'No',\n",
    "                        'Recommended Analysis': 'Parametric' if p_val > 0.05 else 'Non-Parametric'\n",
    "                    })\n",
    "    return pd.DataFrame(report)\n",
    "\n",
    "# --- EXECUTION ---\n",
    "raw_df = pd.read_csv('Data_TableTennis.csv', sep=';')\n",
    "df = load_and_preprocess('Data_TableTennis.csv')\n",
    "\n",
    "# Expanded mapping for reliability (Trial 1 vs Trial 2)\n",
    "reliability_vars = {\n",
    "    'SJ (cm)': ['SJ 1', 'SJ 2'],\n",
    "    'CMJ (cm)': ['CMJ 1', 'CMJ 2'],\n",
    "    'RSI 15cm': ['Drop 15 1 RSI', 'Drop 15 2 RSI'],\n",
    "    'RSI 30cm': ['Drop 30 1 RSI', 'Drop 30 2 RSI'],\n",
    "    'RSI 45cm': ['Drop 45 1 RSI', 'Drop 45 2 RSI'],\n",
    "    'Sprint 5m (s)': ['Sprint 5m 1', 'Sprint 5m 2'],\n",
    "    'Sprint 10m (s)': ['Sprint 10m 1', 'Sprint 10m 2'],\n",
    "    'T-Test (s)': ['Test T 1', 'Test T 2'],\n",
    "    'Square Test (s)': ['Square 1', 'Square 2'],\n",
    "    'Handgrip Dom (kgf)': ['Handgrip D 1', 'Handgrip D 2'],\n",
    "    'Handgrip Non-Dom (kgf)': ['Handgrip E 1', 'Handgrip E 2']\n",
    "}\n",
    "\n",
    "# Expanded variables for normality check (Using 'Best' values)\n",
    "normality_vars = [\n",
    "    'SJ Best', 'CMJ Best', 'Drop 30 RSI Best', 'Sprint 5m Best', \n",
    "    'Sprint 10m Best', 'Test T Best', 'Square Best', \n",
    "    'Handgrip Total Best', 'Radar Vel Best', 'Target Efficiency'\n",
    "]\n",
    "\n",
    "# 1. OUTPUT RELIABILITY REPORT\n",
    "print(\"======================================================================\")\n",
    "print(\"             RELIABILITY REPORT: CONSISTENCY & PRECISION\")\n",
    "print(\"======================================================================\")\n",
    "rel_results = [calculate_reliability(df, cols, name) for name, cols in reliability_vars.items()]\n",
    "print(pd.DataFrame(rel_results).to_string(index=False))\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# 2. OUTPUT NORMALITY REPORT\n",
    "print(\"\\n======================================================================\")\n",
    "print(\"             NORMALITY REPORT: SHAPIRO-WILK BY GROUP\")\n",
    "print(\"======================================================================\")\n",
    "norm_df = perform_normality_test(df, normality_vars, 'Group', raw_df)\n",
    "print(norm_df.to_string(index=False))\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b4c4392-b54f-4e5e-9972-124cebe9d5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "             CONFIRMATION REPORT: TABLE 1 VALUES\n",
      "             Conv: Convencional | Para: Para-athlete\n",
      "======================================================================\n",
      "\n",
      "[Anthropometry]\n",
      "Body Mass (kg)                 | Conv:  49.53 ± 8.93  | Para:  56.89 ± 7.24 \n",
      "Stature (m)                    | Conv:   1.58 ± 0.09  | Para:   1.63 ± 0.18 \n",
      "Wingspan (m)                   | Conv:   1.63 ± 0.11  | Para:   1.66 ± 0.12 \n",
      "\n",
      "[Neuromuscular Power]\n",
      "Squat Jump (cm)                | Conv:  23.07 ± 5.89  | Para:  21.47 ± 5.32 \n",
      "Countermovement Jump (cm)      | Conv:  25.56 ± 5.54  | Para:  23.30 ± 6.27 \n",
      "CMJ Free Arms (cm)             | Conv:  30.48 ± 7.30  | Para:  27.55 ± 6.92 \n",
      "Standing Long Jump (cm)        | Conv: 170.13 ± 19.84 | Para: 156.31 ± 29.09\n",
      "Handgrip Total (kgf)           | Conv:  29.00 ± 8.07  | Para:  33.15 ± 8.82 \n",
      "\n",
      "[Speed and Agility]\n",
      "5m Sprint (s)                  | Conv:   1.27 ± 0.11  | Para:   1.43 ± 0.33 \n",
      "10m Sprint (s)                 | Conv:   2.14 ± 0.17  | Para:   2.46 ± 0.61 \n",
      "Modified T-Test (s)            | Conv:   6.65 ± 0.77  | Para:   7.61 ± 1.05 \n",
      "Square Test (s)                | Conv:   6.10 ± 0.39  | Para:   6.67 ± 0.75 \n",
      "\n",
      "[Technical Performance]\n",
      "Peak Ball Velocity (km/h)      | Conv:  64.79 ± 5.73  | Para:  52.23 ± 10.83\n",
      "Technical Efficiency (%)       | Conv:  38.60 ± 33.82 | Para:  20.51 ± 21.68\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# =============================================================================\n",
    "# TABLE 1 GENERATOR: DESCRIPTIVE CHARACTERISTICS (Mean ± SD)\n",
    "# Version: 2.0 (Robust Group Identification)\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_clean_descriptive(file_path):\n",
    "    df = pd.read_csv(file_path, sep=';')\n",
    "    \n",
    "    # 1. Limpeza rigorosa de cabeçalhos\n",
    "    df.columns = df.columns.str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "    \n",
    "    # 2. Padronização da coluna de Grupo para evitar KeyError\n",
    "    if 'Group' in df.columns:\n",
    "        df['Group'] = df['Group'].astype(str).str.strip()\n",
    "    \n",
    "    # 3. Conversão numérica (vírgula para ponto e '-' para NaN)\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object' and col != 'Group':\n",
    "            df[col] = df[col].astype(str).str.strip().str.replace(',', '.', regex=False)\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "    return df\n",
    "\n",
    "# --- EXECUÇÃO ---\n",
    "df = load_and_clean_descriptive('Data_TableTennis.csv')\n",
    "\n",
    "# Mapeamento: {'Nome na Tabela': 'Nome exato na Planilha'}\n",
    "variables_map = {\n",
    "    'Anthropometry': {\n",
    "        'Body Mass (kg)': 'Mass',\n",
    "        'Stature (m)': 'Height',\n",
    "        'Wingspan (m)': 'Wingspan'\n",
    "    },\n",
    "    'Neuromuscular Power': {\n",
    "        'Squat Jump (cm)': 'SJ Best',\n",
    "        'Countermovement Jump (cm)': 'CMJ Best',\n",
    "        'CMJ Free Arms (cm)': 'CMJ Free Best',\n",
    "        'Standing Long Jump (cm)': 'Hor Jump Best',\n",
    "        'Handgrip Total (kgf)': 'Handgrip Total Best'\n",
    "    },\n",
    "    'Speed and Agility': {\n",
    "        '5m Sprint (s)': 'Sprint 5m Best',\n",
    "        '10m Sprint (s)': 'Sprint 10m Best',\n",
    "        'Modified T-Test (s)': 'Test T Best',\n",
    "        'Square Test (s)': 'Square Best'\n",
    "    },\n",
    "    'Technical Performance': {\n",
    "        'Peak Ball Velocity (km/h)': 'Radar Vel Best',\n",
    "        'Technical Efficiency (%)': 'Target Efficiency'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Identificação dinâmica dos grupos para evitar erro de chave\n",
    "available_groups = df['Group'].unique()\n",
    "group_conv = [g for g in available_groups if 'Conv' in g][0]\n",
    "group_para = [g for g in available_groups if 'Para' in g or 'Atleta' in g][0]\n",
    "\n",
    "print(\"======================================================================\")\n",
    "print(f\"             CONFIRMATION REPORT: TABLE 1 VALUES\")\n",
    "print(f\"             Conv: {group_conv} | Para: {group_para}\")\n",
    "print(\"======================================================================\")\n",
    "\n",
    "for category, vars_dict in variables_map.items():\n",
    "    print(f\"\\n[{category}]\")\n",
    "    for table_label, csv_col in vars_dict.items():\n",
    "        if csv_col in df.columns:\n",
    "            # Cálculos por grupo\n",
    "            res = df.groupby('Group')[csv_col].agg(['mean', 'std', 'count'])\n",
    "            \n",
    "            # Convencional\n",
    "            m_c = res.loc[group_conv, 'mean']\n",
    "            s_c = res.loc[group_conv, 'std']\n",
    "            \n",
    "            # Para-atleta\n",
    "            m_p = res.loc[group_para, 'mean']\n",
    "            s_p = res.loc[group_para, 'std']\n",
    "            \n",
    "            # Ajuste de escala para Eficiência (0.38 -> 38.6%)\n",
    "            mult = 100 if 'Efficiency' in csv_col else 1\n",
    "            \n",
    "            print(f\"{table_label:<30} | Conv: {m_c*mult:>6.2f} ± {s_c*mult:<5.2f} | Para: {m_p*mult:>6.2f} ± {s_p*mult:<5.2f}\")\n",
    "        else:\n",
    "            print(f\"!!! Column '{csv_col}' not found in CSV !!!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c75546c-51e2-4e03-82a8-7470863d6ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "             RSI ANALYSIS MASTER REPORT (INTRA & INTER GROUP)\n",
      "             Groups found in data: ['Convencional' 'Para-athlete']\n",
      "======================================================================\n",
      "\n",
      ">>> STRATIFIED ANALYSIS: CONVENCIONAL (n = 19)\n",
      "DESCRIPTIVES (Mean ± SD):\n",
      "  Drop 15 RSI Best    : 0.595 ± 0.187\n",
      "  Drop 30 RSI Best    : 0.637 ± 0.209\n",
      "  Drop 45 RSI Best    : 0.599 ± 0.226\n",
      "\n",
      "RM-ANOVA: F = 1.36, p = 0.2689\n",
      "BONFERRONI POST-HOC:\n",
      "  Drop 15 RSI Best vs Drop 30 RSI Best: p-corr = 0.2135\n",
      "  Drop 30 RSI Best vs Drop 45 RSI Best: p-corr = 0.4246\n",
      "\n",
      ">>> STRATIFIED ANALYSIS: PARA-ATHLETE (n = 11)\n",
      "DESCRIPTIVES (Mean ± SD):\n",
      "  Drop 15 RSI Best    : 0.387 ± 0.135\n",
      "  Drop 30 RSI Best    : 0.432 ± 0.134\n",
      "  Drop 45 RSI Best    : 0.374 ± 0.161\n",
      "\n",
      "RM-ANOVA: F = 1.71, p = 0.2063\n",
      "BONFERRONI POST-HOC:\n",
      "  Drop 15 RSI Best vs Drop 30 RSI Best: p-corr = 0.2961\n",
      "  Drop 30 RSI Best vs Drop 45 RSI Best: p-corr = 0.2615\n",
      "\n",
      "======================================================================\n",
      "             STEP 4: INTER-GROUP COMPARISON AT 30CM\n",
      "======================================================================\n",
      "Conventional (n=19) vs Para-athlete (n=11):\n",
      "  T-statistic: 2.92\n",
      "  p-value    : 0.0068\n",
      "  Cohen's d  : 1.11 (Large effect)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "\n",
    "# =============================================================================\n",
    "# STATISTICAL MASTER REPORT: RSI DROP HEIGHT ANALYSIS\n",
    "# Version: 5.0 (Group Correction & Robust Statistics)\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_preprocess(file_path):\n",
    "    df = pd.read_csv(file_path, sep=';')\n",
    "    # Limpeza de cabeçalhos\n",
    "    df.columns = df.columns.str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "    \n",
    "    # Limpeza da coluna Group (Crucial para evitar o erro 'NAN')\n",
    "    if 'Group' in df.columns:\n",
    "        # Preenche vazios com 'Unknown', remove espaços e padroniza\n",
    "        df['Group'] = df['Group'].fillna('Unknown').astype(str).str.strip()\n",
    "    \n",
    "    # Conversão numérica\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object' and col != 'Group' and col != 'ID':\n",
    "            df[col] = df[col].astype(str).str.replace(',', '.', regex=False)\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "def calculate_cohens_d(group1, group2):\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    v1, v2 = np.var(group1, ddof=1), np.var(group2, ddof=1)\n",
    "    pooled_sd = np.sqrt(((n1 - 1) * v1 + (n2 - 1) * v2) / (n1 + n2 - 2))\n",
    "    return (np.mean(group1) - np.mean(group2)) / pooled_sd\n",
    "\n",
    "# --- EXECUÇÃO ---\n",
    "df = load_and_preprocess('Data_TableTennis.csv')\n",
    "rsi_cols = ['Drop 15 RSI Best', 'Drop 30 RSI Best', 'Drop 45 RSI Best']\n",
    "df['ID'] = df['ID'].astype(str)\n",
    "\n",
    "print(\"======================================================================\")\n",
    "print(\"             RSI ANALYSIS MASTER REPORT (INTRA & INTER GROUP)\")\n",
    "print(f\"             Groups found in data: {df['Group'].unique()}\")\n",
    "print(\"======================================================================\")\n",
    "\n",
    "# --- PART 1: INTRA-GROUP ANALYSIS (RM-ANOVA) ---\n",
    "# Filtrando apenas os grupos válidos (Ignorando Unknown ou NAN)\n",
    "valid_groups = [g for g in df['Group'].unique() if g != 'Unknown' and g != 'nan']\n",
    "\n",
    "for group_name in valid_groups:\n",
    "    group_df = df[df['Group'] == group_name][['ID'] + rsi_cols].dropna().drop_duplicates(subset=['ID'])\n",
    "    n_final = len(group_df)\n",
    "    \n",
    "    if n_final < 2: \n",
    "        print(f\"\\n[!] Group {group_name} skipped: Insufficient balanced data (n={n_final})\")\n",
    "        continue\n",
    "\n",
    "    df_long = pd.melt(group_df, id_vars=['ID'], value_vars=rsi_cols, var_name='Height', value_name='RSI')\n",
    "    model = AnovaRM(data=df_long, depvar='RSI', subject='ID', within=['Height']).fit()\n",
    "    \n",
    "    means = group_df[rsi_cols].mean()\n",
    "    stds = group_df[rsi_cols].std()\n",
    "\n",
    "    print(f\"\\n>>> STRATIFIED ANALYSIS: {group_name.upper()} (n = {n_final})\")\n",
    "    print(f\"DESCRIPTIVES (Mean ± SD):\")\n",
    "    for col in rsi_cols:\n",
    "        print(f\"  {col:<20}: {means[col]:.3f} ± {stds[col]:.3f}\")\n",
    "    \n",
    "    f_val = model.anova_table['F Value'].iloc[0]\n",
    "    p_anova = model.anova_table['Pr > F'].iloc[0]\n",
    "    print(f\"\\nRM-ANOVA: F = {f_val:.2f}, p = {p_anova:.4f}\")\n",
    "\n",
    "    print(\"BONFERRONI POST-HOC:\")\n",
    "    pairs = [('Drop 15 RSI Best', 'Drop 30 RSI Best'), \n",
    "             ('Drop 30 RSI Best', 'Drop 45 RSI Best')]\n",
    "    for p1, p2 in pairs:\n",
    "        t_stat, p_pair = stats.ttest_rel(group_df[p1], group_df[p2])\n",
    "        p_corr = min(p_pair * 2, 1.0) # Ajustado para 2 comparações principais\n",
    "        print(f\"  {p1} vs {p2}: p-corr = {p_corr:.4f}\")\n",
    "\n",
    "# --- PART 2: INTER-GROUP COMPARISON (O Gap de 30cm) ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"             STEP 4: INTER-GROUP COMPARISON AT 30CM\")\n",
    "print(\"======================================================================\")\n",
    "\n",
    "target = 'Drop 30 RSI Best'\n",
    "# Identificação automática para não dar 'nan'\n",
    "conv_30 = df[df['Group'].str.contains('Conv', case=False, na=False)][target].dropna()\n",
    "para_30 = df[df['Group'].str.contains('Para', case=False, na=False)][target].dropna()\n",
    "\n",
    "if len(conv_30) > 0 and len(para_30) > 0:\n",
    "    t_stat, p_inter = stats.ttest_ind(conv_30, para_30)\n",
    "    d = calculate_cohens_d(conv_30, para_30)\n",
    "\n",
    "    print(f\"Conventional (n={len(conv_30)}) vs Para-athlete (n={len(para_30)}):\")\n",
    "    print(f\"  T-statistic: {t_stat:.2f}\")\n",
    "    print(f\"  p-value    : {p_inter:.4f}\")\n",
    "    print(f\"  Cohen's d  : {d:.2f} ({'Large' if d > 0.8 else 'Medium' if d > 0.5 else 'Small'} effect)\")\n",
    "else:\n",
    "    print(\"Error: Could not find distinct groups to compare. Check 'Group' column labels.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d12b1185-1f1c-4a56-95a0-e3750ab47e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================\n",
      "             CORRELATION MATRIX: PHYSICAL PREDICTORS VS TECHNICAL PERFORMANCE\n",
      "             Values reported as Spearman's Rho (ρ)\n",
      "======================================================================================\n",
      "Predictor                 | Conv: Vel    | Conv: Eff    | Para: Vel    | Para: Eff   \n",
      "--------------------------------------------------------------------------------------\n",
      "SJ (cm)                   |   0.45       |  -0.28       |  -0.14       |   0.45      \n",
      "CMJ (cm)                  |   0.45       |  -0.26       |  -0.25       |   0.45      \n",
      "CMJ Free Arms (cm)        |   0.41       |  -0.26       |   0.13       |   0.28      \n",
      "Hor. Jump (cm)            |   0.24       |  -0.26       |   0.06       |   0.35      \n",
      "Handgrip Total (kgf)      |   0.32       |  -0.24       |   0.59*      |   0.34      \n",
      "RSI 15 cm                 |   0.39       |  -0.06       |   0.24       |   0.10      \n",
      "RSI 30 cm                 |   0.25       |   0.15       |   0.11       |   0.55      \n",
      "RSI 45 cm                 |   0.37       |  -0.12       |  -0.15       |   0.28      \n",
      "5m Sprint (s)             |  -0.38       |   0.10       |   0.01       |  -0.37      \n",
      "10m Sprint (s)            |  -0.47*      |   0.17       |   0.06       |  -0.28      \n",
      "Modified T-Test (s)       |  -0.49*      |   0.44       |  -0.45       |  -0.50      \n",
      "Square Test (s)           |  -0.38       |   0.39       |  -0.50       |  -0.30      \n",
      "======================================================================================\n",
      "* p < 0.05\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# =============================================================================\n",
    "# BIVARIATE CORRELATIONS: TABLE 2 GENERATOR\n",
    "# Version: 8.0 (Full Predictor Battery)\n",
    "# Method: Spearman's Rho (ρ) with Pairwise Deletion\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_preprocess(file_path):\n",
    "    df = pd.read_csv(file_path, sep=';')\n",
    "    # Limpeza de cabeçalhos e normalização de texto\n",
    "    df.columns = df.columns.str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "    if 'Group' in df.columns:\n",
    "        df['Group'] = df['Group'].astype(str).str.strip()\n",
    "    \n",
    "    # Conversão numérica (vírgula para ponto e tratamento de NaNs)\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object' and col != 'Group':\n",
    "            df[col] = df[col].astype(str).str.replace(',', '.', regex=False)\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "# --- EXECUTION ---\n",
    "df = load_and_preprocess('Data_TableTennis.csv')\n",
    "\n",
    "# Mapeamento de variáveis (conforme nomes na planilha vs nomes na tabela)\n",
    "predictors_map = {\n",
    "    'SJ (cm)': 'SJ Best',\n",
    "    'CMJ (cm)': 'CMJ Best',\n",
    "    'CMJ Free Arms (cm)': 'CMJ Free Best',\n",
    "    'Hor. Jump (cm)': 'Hor Jump Best',\n",
    "    'Handgrip Total (kgf)': 'Handgrip Total Best',\n",
    "    'RSI 15 cm': 'Drop 15 RSI Best',\n",
    "    'RSI 30 cm': 'Drop 30 RSI Best',\n",
    "    'RSI 45 cm': 'Drop 45 RSI Best',\n",
    "    '5m Sprint (s)': 'Sprint 5m Best',\n",
    "    '10m Sprint (s)': 'Sprint 10m Best',\n",
    "    'Modified T-Test (s)': 'Test T Best',\n",
    "    'Square Test (s)': 'Square Best'\n",
    "}\n",
    "\n",
    "outcomes_map = {\n",
    "    'Ball Velocity': 'Radar Vel Best',\n",
    "    'Efficiency': 'Target Efficiency'\n",
    "}\n",
    "\n",
    "groups = ['Convencional', 'Para-athlete']\n",
    "\n",
    "print(\"======================================================================================\")\n",
    "print(\"             CORRELATION MATRIX: PHYSICAL PREDICTORS VS TECHNICAL PERFORMANCE\")\n",
    "print(\"             Values reported as Spearman's Rho (ρ)\")\n",
    "print(\"======================================================================================\")\n",
    "print(f\"{'Predictor':<25} | {'Conv: Vel':<12} | {'Conv: Eff':<12} | {'Para: Vel':<12} | {'Para: Eff':<12}\")\n",
    "print(\"-\" * 86)\n",
    "\n",
    "for label, col_phys in predictors_map.items():\n",
    "    row_results = []\n",
    "    \n",
    "    for group_name in groups:\n",
    "        for out_label, col_tech in outcomes_map.items():\n",
    "            # Filtro por grupo e remoção de NaNs específicos desse par\n",
    "            pair_df = df[df['Group'] == group_name][[col_phys, col_tech]].dropna()\n",
    "            \n",
    "            if len(pair_df) > 3:\n",
    "                rho, p_val = stats.spearmanr(pair_df[col_phys], pair_df[col_tech])\n",
    "                sig = \"*\" if p_val < 0.05 else \"\"\n",
    "                row_results.append(f\"{rho:>6.2f}{sig:<2}\")\n",
    "            else:\n",
    "                row_results.append(f\"{'n/a':<8}\")\n",
    "    \n",
    "    # Impressão da linha formatada\n",
    "    print(f\"{label:<25} | {row_results[0]:<12} | {row_results[1]:<12} | {row_results[2]:<12} | {row_results[3]:<12}\")\n",
    "\n",
    "print(\"=\" * 86)\n",
    "print(\"* p < 0.05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8068bc3d-f91a-4405-b2df-6f7e3b28949c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "             SIMPLE LINEAR REGRESSION ANALYSIS\n",
      "======================================================================\n",
      "\n",
      ">>> GROUP: CONVENCIONAL\n",
      "\n",
      "--- Predicting Ball Velocity (km/h) ---\n",
      "  Predictor: 10m Sprint (s)  | R² = 0.360 | F = 9.57 | p = 0.0066 | Beta = -20.143 (SIGNIFICANT)\n",
      "  Predictor: RSI 30 cm       | R² = 0.074 | F = 1.37 | p = 0.2584 | Beta = 7.472 (non-significant)\n",
      "\n",
      "--- Predicting Efficiency (%) ---\n",
      "  Predictor: 10m Sprint (s)  | R² = 0.002 | F = 0.03 | p = 0.8676 | Beta = 0.081 (non-significant)\n",
      "  Predictor: RSI 30 cm       | R² = 0.049 | F = 0.87 | p = 0.3647 | Beta = 0.356 (non-significant)\n",
      "\n",
      ">>> GROUP: PARA-ATHLETE\n",
      "\n",
      "--- Predicting Ball Velocity (km/h) ---\n",
      "  Predictor: 10m Sprint (s)  | R² = 0.007 | F = 0.08 | p = 0.7847 | Beta = -1.495 (non-significant)\n",
      "  Predictor: RSI 30 cm       | R² = 0.061 | F = 0.58 | p = 0.4652 | Beta = 18.221 (non-significant)\n",
      "\n",
      "--- Predicting Efficiency (%) ---\n",
      "  Predictor: 10m Sprint (s)  | R² = 0.092 | F = 1.11 | p = 0.3142 | Beta = -0.108 (non-significant)\n",
      "  Predictor: RSI 30 cm       | R² = 0.264 | F = 3.23 | p = 0.1058 | Beta = 0.862 (non-significant)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 6: SIMPLE LINEAR REGRESSION MODELS (Updated with F-statistic)\n",
    "# Version: 9.2 (Clean Output - No Warnings)\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_preprocess(file_path):\n",
    "    df = pd.read_csv(file_path, sep=';')\n",
    "    df.columns = df.columns.str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "    if 'Group' in df.columns:\n",
    "        df['Group'] = df['Group'].astype(str).str.strip()\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object' and col not in ['Group', 'ID']:\n",
    "            df[col] = df[col].astype(str).str.replace(',', '.', regex=False)\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "# --- EXECUTION ---\n",
    "df = load_and_preprocess('Data_TableTennis.csv')\n",
    "\n",
    "# Selected predictors and outcomes\n",
    "predictors = {'10m Sprint (s)': 'Sprint 10m Best', 'RSI 30 cm': 'Drop 30 RSI Best'}\n",
    "outcomes = {'Ball Velocity (km/h)': 'Radar Vel Best', 'Efficiency (%)': 'Target Efficiency'}\n",
    "groups = ['Convencional', 'Para-athlete']\n",
    "\n",
    "print(\"======================================================================\")\n",
    "print(\"             SIMPLE LINEAR REGRESSION ANALYSIS\")\n",
    "print(\"======================================================================\")\n",
    "\n",
    "for group in groups:\n",
    "    print(f\"\\n>>> GROUP: {group.upper()}\")\n",
    "    \n",
    "    for out_label, col_tech in outcomes.items():\n",
    "        print(f\"\\n--- Predicting {out_label} ---\")\n",
    "        \n",
    "        for pred_label, col_phys in predictors.items():\n",
    "            subset = df[df['Group'] == group][[col_phys, col_tech]].dropna()\n",
    "            \n",
    "            if len(subset) > 5:\n",
    "                X = subset[col_phys]\n",
    "                y = subset[col_tech]\n",
    "                X = sm.add_constant(X)\n",
    "                \n",
    "                model = sm.OLS(y, X).fit()\n",
    "                \n",
    "                r2 = model.rsquared\n",
    "                f_val = model.fvalue # Extraindo a estatística F\n",
    "                p_val = model.pvalues.iloc[1]\n",
    "                beta = model.params.iloc[1]\n",
    "                \n",
    "                sig = \"SIGNIFICANT\" if p_val < 0.05 else \"non-significant\"\n",
    "                \n",
    "                # Relatório atualizado com o valor F\n",
    "                print(f\"  Predictor: {pred_label:<15} | R² = {r2:.3f} | F = {f_val:.2f} | p = {p_val:.4f} | Beta = {beta:.3f} ({sig})\")\n",
    "            else:\n",
    "                print(f\"  Predictor: {pred_label:<15} | Insufficient data (n={len(subset)})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "074ba5bf-e5d6-43e8-8eec-9c303660104d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "             POST-HOC STATISTICAL POWER ANALYSIS REPORT\n",
      "======================================================================\n",
      "Global Alpha Level: 0.05\n",
      "----------------------------------------------------------------------\n",
      "\n",
      ">>> 1. INDEPENDENT SAMPLES T-TEST (RSI 30cm Comparison)\n",
      "  Sample Sizes        : Conv n=19 | Para n=11 (Ratio=0.58)\n",
      "  Observed Effect (d) : 1.11\n",
      "  ACHIEVED POWER      : 80.7%\n",
      "  * Sensitivity Check : Min effect size for 80% power was d=1.10\n",
      "\n",
      ">>> 2. LINEAR REGRESSION MODELS (F-Test)\n",
      "  [Model A] Conventional: 10m Sprint -> Ball Velocity\n",
      "    Sample Size (n)   : 19\n",
      "    Observed R²       : 0.36\n",
      "    Effect Size (f²)  : 0.562\n",
      "    ACHIEVED POWER    : 86.9% (Robust)\n",
      "\n",
      "  [Model B] Para-athlete: RSI 30cm -> Technical Efficiency\n",
      "    Sample Size (n)   : 11\n",
      "    Observed R²       : 0.264\n",
      "    Effect Size (f²)  : 0.359\n",
      "    ACHIEVED POWER    : 42.7% (Low Sensitivity)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.power import TTestIndPower\n",
    "from scipy.stats import f, ncf\n",
    "\n",
    "# =============================================================================\n",
    "# STATISTICAL POWER AND SENSITIVITY ANALYSIS\n",
    "# Version: 1.0 (G*Power Logic Adaptation)\n",
    "# This script calculates post-hoc power for T-Tests and Linear Regression models\n",
    "# based on the observed effect sizes and sample sizes from the study.\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_regression_power(n, r2, predictors, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Calculates post-hoc power for Linear Regression using the F-test distribution.\n",
    "    Matches G*Power logic: 'Linear multiple regression: Fixed model, R2 deviation from zero'.\n",
    "    \n",
    "    Parameters:\n",
    "    - n: Total sample size\n",
    "    - r2: Observed R-squared\n",
    "    - predictors: Number of predictors (k)\n",
    "    - alpha: Significance level (default 0.05)\n",
    "    \n",
    "    Returns:\n",
    "    - power: Statistical power (1 - beta)\n",
    "    - f2: Cohen's f2 effect size\n",
    "    \"\"\"\n",
    "    df_num = predictors\n",
    "    df_denom = n - predictors - 1\n",
    "    \n",
    "    # Calculate Cohen's f2 from R2\n",
    "    if r2 >= 1.0: return 1.0, float('inf')\n",
    "    f2 = r2 / (1 - r2)\n",
    "    \n",
    "    # Non-centrality parameter (lambda)\n",
    "    # G*Power definition: lambda = f2 * n\n",
    "    ncp = f2 * n\n",
    "    \n",
    "    # Critical F value\n",
    "    f_crit = f.ppf(1 - alpha, df_num, df_denom)\n",
    "    \n",
    "    # Power = 1 - CDF of non-central F at critical value\n",
    "    power_val = 1 - ncf.cdf(f_crit, df_num, df_denom, ncp)\n",
    "    \n",
    "    return power_val, f2\n",
    "\n",
    "# --- EXECUTION PARAMETERS ---\n",
    "\n",
    "# 1. Independent Samples T-Test (Group Comparison)\n",
    "n_conv = 19\n",
    "n_para = 11\n",
    "effect_size_d = 1.11  # Observed Cohen's d for RSI 30cm\n",
    "alpha = 0.05\n",
    "ratio = n_para / n_conv\n",
    "\n",
    "# 2. Regression Models (Observed R2)\n",
    "r2_conv_sprint = 0.360  # 10m Sprint -> Ball Vel (Conventional)\n",
    "r2_para_rsi    = 0.264  # RSI 30cm -> Efficiency (Para)\n",
    "\n",
    "# --- CALCULATIONS ---\n",
    "\n",
    "# A. T-Test Power\n",
    "ttest_analysis = TTestIndPower()\n",
    "power_ttest = ttest_analysis.solve_power(\n",
    "    effect_size=effect_size_d, \n",
    "    nobs1=n_conv, \n",
    "    ratio=ratio, \n",
    "    alpha=alpha, \n",
    "    alternative='two-sided'\n",
    ")\n",
    "\n",
    "# B. Sensitivity Analysis (Min Effect for 80% Power)\n",
    "min_effect_80 = ttest_analysis.solve_power(\n",
    "    effect_size=None, \n",
    "    nobs1=n_conv, \n",
    "    ratio=ratio, \n",
    "    alpha=alpha, \n",
    "    power=0.80, \n",
    "    alternative='two-sided'\n",
    ")\n",
    "\n",
    "# C. Regression Power\n",
    "power_reg_conv, f2_conv = calculate_regression_power(n_conv, r2_conv_sprint, predictors=1)\n",
    "power_reg_para, f2_para = calculate_regression_power(n_para, r2_para_rsi, predictors=1)\n",
    "\n",
    "# --- REPORT GENERATION ---\n",
    "\n",
    "print(\"======================================================================\")\n",
    "print(\"             POST-HOC STATISTICAL POWER ANALYSIS REPORT\")\n",
    "print(\"======================================================================\")\n",
    "print(f\"Global Alpha Level: {alpha}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\n>>> 1. INDEPENDENT SAMPLES T-TEST (RSI 30cm Comparison)\")\n",
    "print(f\"  Sample Sizes        : Conv n={n_conv} | Para n={n_para} (Ratio={ratio:.2f})\")\n",
    "print(f\"  Observed Effect (d) : {effect_size_d}\")\n",
    "print(f\"  ACHIEVED POWER      : {power_ttest:.1%}\")\n",
    "print(f\"  * Sensitivity Check : Min effect size for 80% power was d={min_effect_80:.2f}\")\n",
    "\n",
    "print(\"\\n>>> 2. LINEAR REGRESSION MODELS (F-Test)\")\n",
    "print(f\"  [Model A] Conventional: 10m Sprint -> Ball Velocity\")\n",
    "print(f\"    Sample Size (n)   : {n_conv}\")\n",
    "print(f\"    Observed R²       : {r2_conv_sprint}\")\n",
    "print(f\"    Effect Size (f²)  : {f2_conv:.3f}\")\n",
    "print(f\"    ACHIEVED POWER    : {power_reg_conv:.1%} (Robust)\")\n",
    "\n",
    "print(f\"\\n  [Model B] Para-athlete: RSI 30cm -> Technical Efficiency\")\n",
    "print(f\"    Sample Size (n)   : {n_para}\")\n",
    "print(f\"    Observed R²       : {r2_para_rsi}\")\n",
    "print(f\"    Effect Size (f²)  : {f2_para:.3f}\")\n",
    "print(f\"    ACHIEVED POWER    : {power_reg_para:.1%} (Low Sensitivity)\")\n",
    "\n",
    "print(\"======================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce07a769-5f62-4185-b3d6-ab968acafe5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
